# DevOps 中的部署策略

## 1. 引言

部署是 DevOps 生命周期中的最后一步，但可以说是最关键的一步。你可以编写优雅的代码、彻底测试、通过所有审查——但如果部署失败，用户永远无法看到价值。

传统上，部署是一个手动且高压的过程（“在我机器上能跑”是常见的挫败感）。现代 DevOps 通过让部署 **可复现、自动化、可扩展** 来颠覆这一现状。部署不再是瓶颈，而是集成在 CI/CD 流水线中的 **常规、低风险步骤**。

本文将探讨：

* **虚拟机 vs 容器** 的基础，以及它们为什么对部署很重要。
* 常见部署策略：**滚动更新、蓝绿部署、金丝雀发布**。
* 支撑概念如 **自动扩展** 和 **服务发现**，它们让这些策略在大规模系统中可行。

---

## 2. 虚拟机 (VM) vs 容器

在深入策略之前，首先要了解 **我们部署的环境**。

### 虚拟机 (VM)

* **VM** 本质上是运行在虚拟机管理程序（Hypervisor）上的完整操作系统。
* 每个 VM 有自己的内核、内存和资源，使其与其他 VM **高度隔离**。
* 优点：隔离性强、环境可预测，非常适合在一台机器上运行多个操作系统。
* 缺点：**较重** —— 每台 VM 需要数 GB 存储，启动需要几分钟。

### 容器

* **容器** 是一个轻量级环境，将应用及其依赖打包，但共享宿主操作系统内核。
* 与 VM 相比，容器 **启动更快**、**体积更小**。
* 非常适合 **微服务架构**，可并行运行数十甚至数百个小服务。

### 为什么这对部署很重要

* 企业和遗留系统仍然常用 VM，但可能会拖慢部署速度。
* 容器使现代部署更 **便宜、快速、灵活**。
* 高级部署策略（蓝绿、金丝雀、自动扩展）通常以容器为设计基础。

### 回顾我之前的博客

在我 [后台编程路线图关于容器化与虚拟化的文章](../Roadmap_Backend/14_Container_CN.md) 中，我详细讲解了这些概念：

* **虚拟化** → 隔离性强，兼容遗留应用，但开销大、扩展慢。
* **容器化** → 轻量、可移植、高效；适合云原生应用，但隔离性略低。
* **Docker** 简化了将应用打包为容器。
* **Kubernetes** 可在大规模上编排容器，提供自动扩展、弹性和负载均衡等功能。

➡️ *那篇文章深入讲解了权衡、实际案例，以及 Dockerfile 和 Kubernetes YAML 示例。这里我们只关注为什么这个区分对 DevOps 部署策略重要。*

---

# DevOps 中的部署策略

## 3. 部署策略

应用打包好（VM 或容器）后，下一个挑战是：**如何在不影响用户的情况下发布更新？** DevOps 提供了多种策略来安全、高效地部署。

### 3.1 滚动更新 (Rolling Deployments)

* **定义**：逐台服务器（或容器）更新应用，直到所有实例运行新版本。
* **优点**：

  * 零停机（只要至少有部分旧实例继续提供服务）。
  * 比一次性替换更安全。
* **缺点**：

  * 新旧版本可能暂时重叠。如果不保持向后兼容（例如数据库模式变化），可能出问题。

👉 **Kubernetes 中常用**：滚动更新是默认策略 (`kubectl rollout`)。

---

### 3.2 蓝绿部署 (Blue/Green Deployments)

* **定义**：运行两个完全相同的环境：

  * **蓝色** = 现网生产环境
  * **绿色** = 新版本的预发布环境

![蓝绿部署](../assets/images/DevOps/BlueGreenDeployments.jpg "BlueGreen Deployments")

* 一旦绿色环境准备好并经过测试，流量从蓝色 → 绿色 一步切换。

* **优点**：

  * 回滚几乎瞬间完成（只需切回蓝色）。
  * 风险极低，用户只在新版本稳定时看到更新。

* **缺点**：

  * 基础设施成本翻倍（两个环境必须同时运行）。

💡 **迷你教程思路**：

* 想象一个 **GitLab CI/CD 流水线**：构建 Docker 镜像，部署到绿色环境，运行自动化测试，如果成功，则更新 **Nginx 反向代理** 将流量从蓝色切换到绿色。
* 回滚？只需将代理配置切回蓝色即可。

---

### 3.3 金丝雀发布 (Canary Releases)

* **定义**：将新版本发布给 **小部分用户**（如 5%）。监控无异常后，逐步增加流量，直至 100% 用户使用新版本。

* **优点**：

  * 问题只影响少部分用户。
  * 可在真实生产负载下进行测试。

* **缺点**：

  * 需要复杂的监控和路由配置。

* **行业示例**：Google、Facebook、Netflix 都使用金丝雀发布以安全地大规模交付更新。

---

## 4. 扩展与服务管理

部署并非代码上线就结束。应用需要应对 **流量高峰、故障，以及动态服务发现**。

### 4.1 什么是自动扩展 (Autoscaling)？

* **定义**：根据负载自动调整服务器或容器数量。

![AWS 自动扩展](../assets/images/DevOps/AWS_Auto_Scaling.png "AWS Auto Scaling")

* **工作原理**：

  * CPU 使用率飙升时，自动启动更多容器。
  * 流量下降时，关闭未使用实例以节约成本。

* **示例**：

  * **AWS Auto Scaling Groups** → 自动扩展 EC2 VM。
  * **Kubernetes 水平 Pod 自动扩展器 (HPA)** → 根据指标自动扩展 Pod。

* **优点**：

  * 成本高效（按需付费）。
  * 防止流量激增导致系统宕机。

---

### 4.2 什么是服务发现 (Service Discovery)？

在微服务架构中，容器不断被创建和销毁。硬编码 IP 地址不可行。

![服务发现](../assets/images/DevOps/service_discovery.png "service discovery")

* **服务发现** = 允许服务动态找到彼此的系统。

* **工作原理**：

  * 新服务实例上线时，会自动注册自己。
  * 其他服务可以按名称查询（而不是 IP）。

* **示例**：

  * **Kubernetes DNS**：每个服务都有稳定的 DNS 名称（如 `auth-service.default.svc.cluster.local`）。
  * **HashiCorp Consul**：服务注册 + 健康检查。
  * **Netflix Eureka**：Spring Cloud 生态常用。

💡 没有服务发现，微服务扩展将是一团糟。有了它，应用可以自由扩缩容，同时仍能相互通信。

---

## 5. 经验总结

* **部署策略**（滚动、蓝绿、金丝雀）在速度、安全和成本之间取得平衡。
* **容器 + CI/CD 流水线** 使高级部署可行且可复现。
* **自动扩展** 确保应用随需求变化自动适应，无需手动运维。
* **服务发现** 使微服务动态扩展而不破坏连接。
* 黄金法则：**自动化降低风险，加快交付，比人工操作更可扩展。**

---

## 6. 下一步

既然我们已经讲了 **部署策略与扩展**，下一步是 **监控与可观测性**。

➡️ 如何判断应用健康？如何在用户抱怨之前发现问题？下一篇文章我们将讲：

* 日志、指标与追踪。
* 工具：**Prometheus、Grafana、ELK、Sentry**。
* 构建 **可观测优先的 DevOps 文化**。

---
